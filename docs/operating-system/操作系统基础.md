# 操作系统基础

操作系统本质上是一个运行在计算机上的**软件程序** ，用于**管理计算机硬件和软件资源。**

**操作系统存在屏蔽了硬件层的复杂性。** 操作系统就像是硬件使用的负责人，统筹着各种相关事项。

**操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理**。 内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。



#### 基本特征

**1. 并发**

并发是指**宏观**上在一段时间内能同时运行多个程序，而并行则指**同一时刻**能运行多个指令。

**2. 共享**

共享是指系统中的资源可以被多个并发进程共同使用。

有两种共享方式：互斥共享和同时共享。互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。

**3. 虚拟**

虚拟技术把一个物理实体转换为多个逻辑实体。

主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。

多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

**4. 异步**

异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。



系统调用：**凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，**都必须**通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。**

Linux 的系统调用主要有以下这些：

| Task     | Commands                    |
| -------- | --------------------------- |
| 进程控制 | fork(); exit(); wait();     |
| 进程通信 | pipe(); shmget(); mmap();   |
| 文件操作 | open(); read(); write();    |
| 设备操作 | ioctl(); read(); write();   |
| 信息维护 | getpid(); alarm(); sleep(); |
| 安全     | chmod(); umask(); chown();  |



**操作系统有哪些章节？字节跳动教育后端实习四面问到**

\1. 进程管理

进程控制（状态间转换）、进程同步、进程通信、死锁处理、处理机调度等。

\2. 内存管理

内存分配、地址映射、内存保护与共享、虚拟内存等。

\3. 文件管理

文件存储空间的管理、目录管理、文件读写管理和保护等。

\4. 设备管理

完成设备的请求或释放，方便用户使用各种设备，并提高设备的利用率。

主要包括缓冲管理、设备分配、设备处理、虛拟设备等。



#### 中断分类

中断是指计算机运行过程中，出现某些**意外情况**需主机干预时，机器能**自动停止正在运行的程序**并转入处理新情况的程序，处理完毕后又返回原被暂停的程序继续运行。

从本质上来讲，中断是一种电信号，当设备有某种事件发生时，它就会产生中断，通过总线把电信号发送给中断控制器。

\1. 异常

又称同步中断，是在指令执行时由**CPU主动产生**的，受到CPU控制，其执行点是可控的。异常可分为故障（fault）、陷阱（trap）和终止（abort）三类。如非法操作码、地址越界、算术溢出等。

其余中断是CPU被动接收到的，称为异步中断/外中断。

\2. 外中断

又称异步中断。由 CPU 执行指令以外的事件引起，由外设发出的电信号引起，其发生时间不可预测，如 **I/O 完成中断**，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有**时钟中断、控制台中断**等。

\3. 陷入

又称软中断。在用户程序中使用系统调用，模式切换时，需要软中断。

为了保护系统数据不受非法篡改，需要审核陷入内核的这种访问是否合法，这种审核也叫**软中断**，如果非法，就会中断访问。黑客攻入就是巧妙得绕过了软中断。需要不断打补丁，关掉漏洞。



# 进程

### 进程与线程的区别

**进程是资源分配的最小单位，线程是CPU调度的最小单位。**

- **拥有资源：进程是资源分配的最小单位；线程属于某个进程，共享其资源。**

- - 进程拥有完整的虚拟内存地址空间，不同进程有不同虚拟地址空间，同一进程的不同线程共享同一地址空间。

- **是否独立：进程可以看作独立应用（独立的调度、管理、资源分配），线程不能看成独立应用，必须依存于某个应用程序。**线程是进程划分成的更小的运行单位。线程执行开销小，但不利于资源的管理和保护

- - **进程有独立的地址空间，相互不影响，线程只是进程的不同执行路径。**
  - 一个进程崩溃后，在保护模式下不会对其他进程产生影响；而一个线程崩溃，所在的进程都会崩溃。因此多进程的程序要比多线程的程序健壮。

- **切换开销：进程切换比线程切换开销大。**

- - 由于**创建或撤销**进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
  - 在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

- **通信：**线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助IPC。



#### 协程

**协程routine，**是一种比线程更加轻量级的存在。**一个线程可以有多个协程，协程只是线程内的内存模型。**协程不是被操作系统内核所管理，而**完全是由程序所控制（也就是在用户态执行）**。不同于函数只能顺序执行完一个函数再执行下一个，协程在子程序内部是可中断的，然后转而执行别的子程序，在适当的时候再返回来接着执行。

**协程的特点在于是一个线程执行，那和多线程比，协程有何优势？**

极高的执行效率：**因为子程序切换不是线程切换，而是由程序自身控制**，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显；**协程的切换开销更小，不需要cpu的切换，只需要内存的切换开销。**

**不需要多线程的锁机制：串行执行。**因为只有一个线程，也不存在同时写变量冲突，在协程中控制**共享资源不加锁**，只需要判断状态就好了，所以执行效率比多线程高很多。

**Go 语言支持并发，我们只需要通过 go 关键字来开启 goroutine 即可。**

goroutine 是轻量级线程，goroutine 的调度是由 Golang 运行时进行管理的。

**lua脚本就是基于协程机制完成nginx开发，很少直接用c，c++了现在。**



#### 进程的状态

- **创建状态(new)** ：进程正在被创建，尚未到就绪状态。
- **就绪状态(ready)** ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- **运行状态(running)** ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- **阻塞状态(block/waiting)** ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- **结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。
- **挂起(Suspend)** **：**在内存资源不足的情况下，有的进程被暂时调离出内存，当条件允许的时候，会被操作系统再次调回内存。



### 进程的通信

进程同步与进程通信很容易混淆，它们的区别在于：

- **进程同步：**对资源使用的时候进程之间的协调，**控制多个进程按一定顺序执行；**
- **进程通信：进程间传输信息。**

**进程通信是一种手段，而进程同步是一种目的。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。**

每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为**进程间通信（IPC，InterProcess Communication）**

大概有 7 种常见的进程间的通信方式。

下面这部分总结参考了:[《进程间通信 IPC (InterProcess Communication)》](https://www.jianshu.com/p/c1015f5ffa74) 这篇文章，推荐阅读，总结的非常不错。

**1. 管道/匿名管道(Pipes)** ：

管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

\#include <unistd.h> int pipe(int fd[2]);

它具有以下限制：

- 只能在父子进程/兄弟进程中使用
- 只支持半双工通信（单向交替传输）

**2.命名管道(Names Pipes)** : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。命名管道严格遵循**先进先出(first in first out)**。命名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。

\#include <sys/stat.h> int mkfifo(const char *path, mode_t mode); int mkfifoat(int fd, const char *path, mode_t mode);

**3. 消息队列(Message Queuing)** ：消息队列是消息的链表，具有特定的格式，存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中**，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。**消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺。

**相比于命名管道，消息队列具有以下优点：**

- 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
- 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
- 读进程可以实现消息的随机查询，可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

**4. 信号(Signal)** ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；

**5. 信号量(Semaphores)** ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。

**6. 共享内存(Shared memory)** ：多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。**因为数据不需要在进程之间复制，所以这是最快最有用的一种 IPC。**

这种方式需要依靠某种同步操作，如互斥锁和信号量等。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

**7. 套接字(Sockets)** : 不同机器间的进程的网络通信。



#### 线程间的同步的方式

**同步：控制多个进程/线程按一定顺序执行；**

线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：

1. **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
2. **信号量(Semphares)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
3. **事件(Event)** :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操



### 进程的调度算法

**调度的评价标准**

**（1） CPU利用率**

**（2） 系统吞吐量**

**（3） 周转时间**

**（4） 等待时间**

**（5） 响应时间**

**1. 批处理系统**

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

**1.1 先来先服务 first-come first-serverd（FCFS）**

非抢占式的调度算法，按照请求的顺序进行调度。直到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。

优缺点：有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**1.2 短作业优先 shortest job first（SJF）**

非抢占式的调度算法，按估计运行时间最短的顺序进行调度。直到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。

优缺点：**仅照顾了短进程而忽略了长进程** 。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**1.3 最短剩余时间优先 shortest remaining time next（SRTN）**

最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

**2. 交互式系统**

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

**2.1 时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。将所有就绪进程按 FCFS 的原则排成一个队列，每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系（Trade-Off）：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

**2.2 优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以**根据内存要求，时间要求或任何其他资源要求**来确定优先级。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**2.3 多级反馈队列调度算法** ：可以将这种调度算法看成是**时间片轮转调度算法和优先级调度算法的结合。**多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。

比如：一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

**每个队列优先权也不同，最上面的优先权最高。**因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

**3. 实时系统**

**实时系统要求一个请求在一个确定时间内得到响应。**

**分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。**

**3.1  EDF算法（Earliest DeadLine First）**

根据任务的最早截至时间来确定任务的优先级，即任务的开始截止时间/结束截止时间越早，其优先级越高。在实现该算法时，要求系统中保持一个实时任务就绪队列，该队列按各任务的截止时间的早晚排序。

对于周期截止时间的任务，可以预测，则采用抢占式算法。

对于非周期性的具有截止时间的任务，不可预测，一般采用允许CPU空闲的EDF调度算法，指优先调度最早截止时间的任务，并将它执行完毕才调度下一个任务(非抢占方式)。

**3.2 速度单调调度算法**

**通俗讲，就是速度(频率)越高，优先级越高**

基于周期给优先级**，周期越短，频率越高，优先级越高**



### 死锁

**产生死锁的条件 前三点是必要条件，第四点是充分条件**

**• Mutual exclusion(互斥)** 资源互斥使用，一次只允许一个进程使用

**• Hold-and-wait(保持并等待)**  申请到了资源，占用这个资源，并申请其他资源

**• No preemption(不剥夺)**  申请到资源，无法剥夺

**• Circular wait(环路等待)**  前三个条件的可能结果，出现环路等待了，一定会死锁

字节一面问到实际生活的死锁例子，比如说卖苹果，买家要先拿到东西再付钱，卖家要先拿到钱再给东西。

怎么解决，tryacquire一段时间，获取不到就不要了。

**预防死锁**

**间接方法，禁止前3个条件之一的发生：**

**1.禁止“保持并等待”条件**：要求进程**一次性地申请其所需的全部资源**。若系统中没有足够的资源可分配给它，则进程阻塞。 

**效率和资源利用率很低：**

必须知道进程整个生存区(从产生到结束)需要用到哪些资源。还必须全拿到

要拿到全部资源，有可能最后才用一下，也有可能if else 执行过程中只用一小部分，但需要全部申请占用。

**2.禁止“不剥夺”条件**

若一个进程申请的资源被另一个进程占有，OS可以剥夺低优先权进程的资源分配给高

优先权的进程（要求此类可剥夺资源的状态易于保存和恢复，否则不能剥夺，比如正在打印，结果剥夺了，前面打印都无效了）

**直接方法**

**禁止“环路等待”条件：**将系统的所有资源按类型不同进行**线性排队**，并赋予不同的序号。进程对某类资源的申请只能按照序号递增的方式进行。  低效

以上间接或直接的预防死锁的方法都依靠较强的限制条件实现，性能会受很大的影响

**避免死锁——银行家算法——实际上是避免系统进入不安全状态，时刻都能找到一个安全序列**

**其他进程的资源分配都会影响本进程，如果资源申请可能使系统处于不安全状态，进程会阻塞等待。因此进程在系统中的运行是不可预测的，异步运行，走走停停。**

•避免死锁的关键在于为进程分配资源之前，**首先通过计算，判断此次分配是否会导致死锁**，只有不会导致死锁的分配才可实行。

要求知道所有的进程整个运行期间用到哪些资源以及系统能提供哪些资源。



# 内存管理

### CPU 寻址，为什么需要虚拟地址空间?

现代处理器使用的是一种称为 **虚拟寻址(Virtual Addressing)** 的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 

**为什么要有虚拟地址空间呢？**

先从没有虚拟地址空间的时候说起吧！没有虚拟地址空间的时候，**程序都是直接访问和操作的都是物理内存** 。但是这样有什么问题呢？

1. 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。
2. 想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

**总结来说：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。**

通过虚拟地址访问内存有以下优势：

- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
- 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。



**逻辑(虚拟)地址和物理地址**

我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。逻辑地址是一个相对地址，相对于某个点的第几条语句

物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。物理地址是内存单元真正的地址。

逻辑地址必须转换成物理地址，处理器才能执行



#### 快表和多级页表

不论是快表还是多级页表实际上都利用到了程序的局部性原理。

在分页内存管理中，很重要的两点是：

1. 虚拟地址到物理地址的转换要快。
2. 解决虚拟地址空间大，页表也会很大的问题。

**快表TLB**

为了解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来**加速虚拟地址到物理地址的转换。**我们可以把块表理解为一种特殊的**高速缓冲存储器（Cache）**，其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

**多级页表**

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景，具体可以查看下面这篇文章

- [多级页表如何节约内存](https://www.polarxiong.com/archives/多级页表如何节约内存.html)

**总结**

为了提高内存的空间性能，提出了多级页表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即 TLB）的概念。 



### 内存管理机制

**操作系统的内存管理机制了解吗？内存管理有哪几种方式?**

简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如**块式管理** 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**。

1. **块式管理** ： 远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
2. **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
3. **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。
4. **段页式管理机制** 。段页式管理机制结合了段式管理和页式管理的优点。程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。



**分页机制和分段机制的共同点和区别**

1. **共同点** ：

- - 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。
  - 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。

1. **区别** ：

- - 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
  - 目的不同：分页仅仅是为了满足操作系统内存管理的需求，主要用于提高内存的利用率，消除外零头，抑制内零头；实现虚拟内存，从而获得更大的地址空间，而段是逻辑信息的单位，在程序中可以体现为代码段（子函数），数据段，有利于**模块化**程序设计。
  - 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
  - 地址空间的维度：对于用户来说，分页是一维地址空间，分段是二维的（第几段的第几行）。例如分页例题1502，1502/页的大小可以算出页号和页内偏移量



#### 虚拟内存

**什么是虚拟内存(Virtual Memory)?**

**虚拟内存** 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片（页），还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。**当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。**

通过**虚拟内存**可以让程序可以**把内存扩展到硬盘空间。**



局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。



#### 特点

1. 一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；
2. **缺页中断**：如果**需执行的指令或访问的数据尚未在内存**（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段**调入到内存**，然后继续执行程序；
3. **虚拟地址空间** ：逻辑地址到物理地址的变换。



####  页面置换算法

👨‍💻**面试官** ：虚拟内存管理很重要的一个概念就是页面置换算法。那你说一下 **页面置换算法的作用?常见的页面置换算法有哪些?**

🙋 **我** ：

这个题目经常作为笔试题出现，网上已经给出了很不错的回答，我这里只是总结整理了一下。

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。

**缺页中断** 就是要访问的**页**不在主存，需要操作系统将其调入主存后再进行访问。 在这个时候，被内存映射的文件实际上成了一个分页交换文件。

当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。

- **OPT 页面置换算法（最佳页面置换算法）** ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- **LRU （Least Currently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** :  该置换算法选择在之前时期使用最少的页面作为淘汰页。

**==要会写LRU和LFU==**


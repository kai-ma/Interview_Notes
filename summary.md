# Java

## Collection

### HashMap

**重写 `equals` 时必须重写 `hashCode` 方法？**

**保证如果两个对象相等，则 hashcode 一定也是相同的。这是规定。**否则当把这个对象放入`HashMap`，有可能添加重复key。



当两个不同的键对象的hashcode相同时，它们会储存在同一个bucket位置的链表中。键对象的equals()方法用来找到键值对。

**创建HashMap对象默认情况下，数组大小为16。**

开始扩容的大小=原来的数组大小*loadFactor   16*0.75=12 超过12个元素，进行扩容

扩容是一个非常消耗性能的操作，所以如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能

扩容后大小是原来的2倍，其中加载因子loadFactor的默认值为0.75，这个参数可以再创建对象时在构造方法中指定。

**转换为红黑树的条件：链表的长度达到8个或数组的长度达到64个**



## 多线程

### 线程安全的实现方式

- ThreadLocal——空间换时间

#### ThreadLocal

**ThreadLocal即线程本地存储，ThreadLocal会为每一个线程提供一个独立的变量副本，因此避免了多线程竞争。**



### JUC中的容器

![juc中的并发容器](images/summary/JUC Collection.png)

#### ConcurrentHashMap 🔥

线程安全的HashMap

JDK1.7  分段的数组+链表。JDK1.8之后，数组+链表/红黑二叉树，与HashMap1.8相同。

实现：从不同段没有竞争到不hash冲突就没有锁竞争。JDK1.7 分段锁，Segment 实现了 `ReentrantLock`。JDK1.8 并发控制使用 `synchronized` 和 CAS 来操作，`synchronized` 只锁定当前链表或红黑二叉树的首节点。   

1.8之后底层原理：

- get方法无锁实现，原因：Node的value，next都用volatile修饰。table[]也用volatile修饰，保证了修改的可见性。 
- put方法，先读tabAt，若bucket为空，for循环+CAS。若不为空，如果正在扩容，当前线程帮助一起扩容。如果没有扩容，用synchronized锁，锁的粒度是结点锁，锁住这个bucket的操作。其余bucket可以并发执行。
- remove方法，先读tabAt，若bucket为空退出for循环。若不为空，如果正在扩容，当前线程帮助一起扩容。如果没有扩容，用synchronized锁，锁的粒度是结点锁，锁住这个bucket的操作。其余bucket可以并发执行。

读读互不影响，写写互斥。读写也不互斥，不过在某些情况下读取是弱一致性的，如线程A调用putAll写入大量数据，期间线程B调用get，则只能get到目前为止已经顺利插入的部分数据。这也是为什么ConcurrentHashMap不能完全替代HashTable。

#### CopyOnWriteArrayList/CopyOnWriteArraySet

线程安全的ArrayList/Set

`CopyOnWriteArrayList` 支持读写分离，读取是快照读，与MVCC原理一样，完全不用加锁。写入操作不会修改原数组，而是拷贝一个数组，对副本进行修改，写完之后再将内部维护的数组指向新的数组。因此读写互不影响，只有写写才会互斥。适合于多读，少写场景（不断创建副本/写操作要加锁），小对象场景。

缺点：大对象内存占用严重。读操作与使用迭代器是弱一致性的，读不到新写入的数据。

`CopyOnWriteArraySet`底层使用`CopyOnWriteArrayList` ，性质相同。

#### ConcurrentLinkedQueue

线程安全的LinkedList，线程安全的非阻塞队列。

线程安全的队列分为阻塞队列和非阻塞队列，阻塞队列通过加锁来实现，非阻塞队列通过 CAS 操作实现。`ConcurrentLinkedQueue` 用CAS+volatile实现了非阻塞的链表队列，适用于高并发追求高性能的场景。与阻塞队列相比的优缺点和CAS与锁的优缺点分析一样。

`ConcurrentLinkedDeque`与它类似，是线程安全的 `Deque`。

#### BlockingQueue

常用的三个实现类：`ArrayBlockingQueue`、`LinkedBlockingQueue`、`PriorityBlockingQueue`。都使用`ReentrantLock`。

`ArrayBlockingQueue`有界，采用经典的双Condition实现，默认非公平，可选择公平锁。

`LinkedBlockingQueue`单向链表，默认无界，初始化可以指定边界，不支持公平锁。

`PriorityBlockingQueue`无界，可以指定初始化大小，但会动态扩容。要么是Comparable的，要么传入Comparator。

还有一种：`SynchronousQueue`，在`CachedThreadPool`会用到。虽说是队列，但不会为队列中元素维护存储空间。是同步队列，读线程和写线程需要同步，一个读线程匹配一个写线程。数据必须从某个写线程交给某个读线程，而不是写到某个队列中等待被消费。

#### ConcurrentSkipListMap

依靠CAS实现线程安全，底层是跳表结构，用空间换时间。有序场景下比CurrentHashMap效率高。



# 操作系统

操作系统本质上是一个运行在计算机上的**软件程序** ，用于**管理计算机硬件和软件资源。**

**操作系统存在屏蔽了硬件层的复杂性。** 操作系统就像是硬件使用的负责人，统筹着各种相关事项。

**操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理**。 内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。



#### 基本特征

**1. 并发**

并发是指**宏观**上在一段时间内能同时运行多个程序，而并行则指**同一时刻**能运行多个指令。

**2. 共享**

共享是指系统中的资源可以被多个并发进程共同使用。

有两种共享方式：互斥共享和同时共享。互斥共享的资源称为临界资源，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。

**3. 虚拟**

虚拟技术把一个物理实体转换为多个逻辑实体。

主要有两种虚拟技术：时（时间）分复用技术和空（空间）分复用技术。

多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

**4. 异步**

异步指进程不是一次性执行完毕，而是走走停停，以不可知的速度向前推进。



系统调用：**凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，**都必须**通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。**

Linux 的系统调用主要有以下这些：

| Task     | Commands                    |
| -------- | --------------------------- |
| 进程控制 | fork(); exit(); wait();     |
| 进程通信 | pipe(); shmget(); mmap();   |
| 文件操作 | open(); read(); write();    |
| 设备操作 | ioctl(); read(); write();   |
| 信息维护 | getpid(); alarm(); sleep(); |
| 安全     | chmod(); umask(); chown();  |



**操作系统有哪些章节？字节跳动教育后端实习四面问到**

\1. 进程管理

进程控制（状态间转换）、进程同步、进程通信、死锁处理、处理机调度等。

\2. 内存管理

内存分配、地址映射、内存保护与共享、虚拟内存等。

\3. 文件管理

文件存储空间的管理、目录管理、文件读写管理和保护等。

\4. 设备管理

完成设备的请求或释放，方便用户使用各种设备，并提高设备的利用率。

主要包括缓冲管理、设备分配、设备处理、虛拟设备等。



#### 中断分类

中断是指计算机运行过程中，出现某些**意外情况**需主机干预时，机器能**自动停止正在运行的程序**并转入处理新情况的程序，处理完毕后又返回原被暂停的程序继续运行。

从本质上来讲，中断是一种电信号，当设备有某种事件发生时，它就会产生中断，通过总线把电信号发送给中断控制器。

\1. 异常

又称同步中断，是在指令执行时由**CPU主动产生**的，受到CPU控制，其执行点是可控的。异常可分为故障（fault）、陷阱（trap）和终止（abort）三类。如非法操作码、地址越界、算术溢出等。

其余中断是CPU被动接收到的，称为异步中断/外中断。

\2. 外中断

又称异步中断。由 CPU 执行指令以外的事件引起，由外设发出的电信号引起，其发生时间不可预测，如 **I/O 完成中断**，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有**时钟中断、控制台中断**等。

\3. 陷入

又称软中断。在用户程序中使用系统调用，模式切换时，需要软中断。

为了保护系统数据不受非法篡改，需要审核陷入内核的这种访问是否合法，这种审核也叫**软中断**，如果非法，就会中断访问。黑客攻入就是巧妙得绕过了软中断。需要不断打补丁，关掉漏洞。



## 进程

### 进程与线程的区别

**进程是资源分配的最小单位，线程是CPU调度的最小单位。**

- **拥有资源：进程是资源分配的最小单位；线程属于某个进程，共享其资源。**

- - 进程拥有完整的虚拟内存地址空间，不同进程有不同虚拟地址空间，同一进程的不同线程共享同一地址空间。

- **是否独立：进程可以看作独立应用（独立的调度、管理、资源分配），线程不能看成独立应用，必须依存于某个应用程序。**线程是进程划分成的更小的运行单位。线程执行开销小，但不利于资源的管理和保护

- - **进程有独立的地址空间，相互不影响，线程只是进程的不同执行路径。**
  - 一个进程崩溃后，在保护模式下不会对其他进程产生影响；而一个线程崩溃，所在的进程都会崩溃。因此多进程的程序要比多线程的程序健壮。

- **切换开销：进程切换比线程切换开销大。**

- - 由于**创建或撤销**进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。
  - 在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

- **通信：**线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助IPC。



#### 协程

**协程routine，**是一种比线程更加轻量级的存在。**一个线程可以有多个协程，协程只是线程内的内存模型。**协程不是被操作系统内核所管理，而**完全是由程序所控制（也就是在用户态执行）**。不同于函数只能顺序执行完一个函数再执行下一个，协程在子程序内部是可中断的，然后转而执行别的子程序，在适当的时候再返回来接着执行。

**协程的特点在于是一个线程执行，那和多线程比，协程有何优势？**

极高的执行效率：**因为子程序切换不是线程切换，而是由程序自身控制**，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显；**协程的切换开销更小，不需要cpu的切换，只需要内存的切换开销。**

**不需要多线程的锁机制：串行执行。**因为只有一个线程，也不存在同时写变量冲突，在协程中控制**共享资源不加锁**，只需要判断状态就好了，所以执行效率比多线程高很多。

**Go 语言支持并发，我们只需要通过 go 关键字来开启 goroutine 即可。**

goroutine 是轻量级线程，goroutine 的调度是由 Golang 运行时进行管理的。

**lua脚本就是基于协程机制完成nginx开发，很少直接用c，c++了现在。**



#### 进程的状态

- **创建状态(new)** ：进程正在被创建，尚未到就绪状态。
- **就绪状态(ready)** ：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源(处理器分配的时间片)即可运行。
- **运行状态(running)** ：进程正在处理器上上运行(单核 CPU 下任意时刻只有一个进程处于运行状态)。
- **阻塞状态(block/waiting)** ：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- **结束状态(terminated)** ：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。
- **挂起(Suspend)** **：**在内存资源不足的情况下，有的进程被暂时调离出内存，当条件允许的时候，会被操作系统再次调回内存。



### 进程的通信

[《进程间通信 IPC (InterProcess Communication)》](https://www.jianshu.com/p/c1015f5ffa74)

进程通信是一种手段，而进程同步是一种目的（对资源使用的时候进程之间的协调，控制多个进程按一定顺序执行；）。**也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。**

每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为**进程间通信（IPC，InterProcess Communication）**

大概有 7 种常见的进程间的通信方式。

**1. 匿名管道(Pipes)** 

匿名管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

\#include <unistd.h> int pipe(int fd[2]);

- 以内存文件方式存在
- 匿名管道由于没有名字，只能用于亲缘关系（在父子进程/兄弟进程）的进程间通信。
- 只支持半双工通信（单向交替传输）

**2.命名管道(Names Pipes)** 

- 以磁盘文件方式存在
- 可以实现本机任意两个进程通信
- 严格遵循**先进先出(first in first out)**。

**3. 消息队列(Message Queuing)** 

- 存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。
- 管道和消息队列的通信数据都是先进先出的原则。
- 克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺。

消息队列是消息的链表，具有特定的格式，存放在内存中并由消息队列标识符标识。

**相比于命名管道，消息队列具有以下优点：**

- 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
- 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
- 读进程可以实现消息的随机查询，可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

**4. 信号(Signal)** ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；

**5. 信号量(Semaphores)** ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。

**6. 共享内存(Shared memory)** ：多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。==**因为数据不需要在进程之间复制，所以这是最快最有用的一种 IPC。**==

这种方式需要依靠某种同步操作，如互斥锁和信号量等。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

**7. 套接字(Sockets)** : 不同机器间的进程的网络通信。



#### 线程间的同步的方式

**同步：控制多个进程/线程按一定顺序执行；**

线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：

1. **互斥量(Mutex)**：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
2. **信号量(Semphares)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量
3. **事件(Event)** :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操



### 进程的调度算法

**调度的评价标准**

**（1） CPU利用率**

**（2） 系统吞吐量**

**（3） 周转时间**

**（4） 等待时间**

**（5） 响应时间**

**1. 批处理系统**

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

**1.1 先来先服务 first-come first-serverd（FCFS）**

非抢占式的调度算法，按照请求的顺序进行调度。直到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。

优缺点：有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**1.2 短作业优先 shortest job first（SJF）**

非抢占式的调度算法，按估计运行时间最短的顺序进行调度。直到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。

优缺点：**仅照顾了短进程而忽略了长进程** 。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**1.3 最短剩余时间优先 shortest remaining time next（SRTN）**

最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

**2. 交互式系统**

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

**2.1 时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。将所有就绪进程按 FCFS 的原则排成一个队列，每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系（Trade-Off）：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

**2.2 优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以**根据内存要求，时间要求或任何其他资源要求**来确定优先级。为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**2.3 多级反馈队列调度算法** ：可以将这种调度算法看成是**时间片轮转调度算法和优先级调度算法的结合。**多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。

比如：一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

**每个队列优先权也不同，最上面的优先权最高。**因此只有上一个队列没有进程在排队，才能调度当前队列上的进程。

**3. 实时系统**

**实时系统要求一个请求在一个确定时间内得到响应。**

**分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。**

**3.1  EDF算法（Earliest DeadLine First）**

根据任务的最早截至时间来确定任务的优先级，即任务的开始截止时间/结束截止时间越早，其优先级越高。在实现该算法时，要求系统中保持一个实时任务就绪队列，该队列按各任务的截止时间的早晚排序。

对于周期截止时间的任务，可以预测，则采用抢占式算法。

对于非周期性的具有截止时间的任务，不可预测，一般采用允许CPU空闲的EDF调度算法，指优先调度最早截止时间的任务，并将它执行完毕才调度下一个任务(非抢占方式)。

**3.2 速度单调调度算法**

**通俗讲，就是速度(频率)越高，优先级越高**

基于周期给优先级**，周期越短，频率越高，优先级越高**



### 死锁

**产生死锁的条件 前三点是必要条件，第四点是充分条件**

**• Mutual exclusion(互斥)** 资源互斥使用，一次只允许一个进程使用

**• Hold-and-wait(保持并等待)**  申请到了资源，占用这个资源，并申请其他资源

**• No preemption(不剥夺)**  申请到资源，无法剥夺

**• Circular wait(环路等待)**  前三个条件的可能结果，出现环路等待了，一定会死锁

字节一面问到实际生活的死锁例子，比如说卖苹果，买家要先拿到东西再付钱，卖家要先拿到钱再给东西。

怎么解决，tryacquire一段时间，获取不到就不要了。

**预防死锁**

**间接方法，禁止前3个条件之一的发生：**

**1.禁止“保持并等待”条件**：要求进程**一次性地申请其所需的全部资源**。若系统中没有足够的资源可分配给它，则进程阻塞。 

**效率和资源利用率很低：**

必须知道进程整个生存区(从产生到结束)需要用到哪些资源。还必须全拿到

要拿到全部资源，有可能最后才用一下，也有可能if else 执行过程中只用一小部分，但需要全部申请占用。

**2.禁止“不剥夺”条件**

若一个进程申请的资源被另一个进程占有，OS可以剥夺低优先权进程的资源分配给高

优先权的进程（要求此类可剥夺资源的状态易于保存和恢复，否则不能剥夺，比如正在打印，结果剥夺了，前面打印都无效了）

**直接方法**

**禁止“环路等待”条件：**将系统的所有资源按类型不同进行**线性排队**，并赋予不同的序号。进程对某类资源的申请只能按照序号递增的方式进行。  低效

以上间接或直接的预防死锁的方法都依靠较强的限制条件实现，性能会受很大的影响

**避免死锁——银行家算法——实际上是避免系统进入不安全状态，时刻都能找到一个安全序列**

**其他进程的资源分配都会影响本进程，如果资源申请可能使系统处于不安全状态，进程会阻塞等待。因此进程在系统中的运行是不可预测的，异步运行，走走停停。**

•避免死锁的关键在于为进程分配资源之前，**首先通过计算，判断此次分配是否会导致死锁**，只有不会导致死锁的分配才可实行。

要求知道所有的进程整个运行期间用到哪些资源以及系统能提供哪些资源。



## 内存管理

### 虚拟内存

**什么是虚拟内存(Virtual Memory)?**

**虚拟内存** 使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片（页），还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。**当程序引用到不在物理内存中的页时，由硬件执行必要的映射，将缺失的部分装入物理内存并重新执行失败的指令。**

通过**虚拟内存**可以让程序可以**把内存扩展到硬盘空间。**



局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。



#### 特点

1. 一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；
2. **缺页中断**：如果**需执行的指令或访问的数据尚未在内存**（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段**调入到内存**，然后继续执行程序；
3. **虚拟地址空间** ：逻辑地址到物理地址的变换。



### CPU 寻址，为什么需要虚拟地址空间?

现代处理器使用的是一种称为 **虚拟寻址(Virtual Addressing)** 的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 

**为什么要有虚拟地址空间呢？**

先从没有虚拟地址空间的时候说起吧！没有虚拟地址空间的时候，**程序都是直接访问和操作的都是物理内存** 。但是这样有什么问题呢？

1. 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易（有意或者无意）破坏操作系统，造成操作系统崩溃。
2. 想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行。为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

**总结来说：如果直接把物理地址暴露出来的话会带来严重问题，比如可能对操作系统造成伤害以及给同时运行多个程序造成困难。**

通过虚拟地址访问内存有以下优势：

- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
- 不同进程使用的虚拟地址彼此隔离。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。



#### 逻辑(虚拟)地址和物理地址转换

我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。逻辑地址是一个相对地址，相对于某个点的第几条语句

物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址。**物理地址是内存单元真正的地址。**

逻辑地址必须转换成物理地址，处理器才能执行



**TLB 页号找页框号  页框号+偏移量**  

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。



#### 快表和多级页表

不论是快表还是多级页表实际上都利用到了程序的局部性原理。

在分页内存管理中，很重要的两点是：

1. 虚拟地址到物理地址的转换要快。
2. 解决虚拟地址空间大，页表也会很大的问题。

**快表TLB**

为了解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来**加速虚拟地址到物理地址的转换。**我们可以把块表理解为一种特殊的**高速缓冲存储器（Cache）**，其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。



**多级页表**

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景，具体可以查看下面这篇文章

- [多级页表如何节约内存](https://www.polarxiong.com/archives/多级页表如何节约内存.html)

**总结**

为了提高内存的空间性能，提出了多级页表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即 TLB）的概念。 



### 内存管理机制

**操作系统的内存管理机制了解吗？内存管理有哪几种方式?**

简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如**块式管理** 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**。

1. **块式管理** ： 远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
2. **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
3. **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。
4. **段页式管理机制** 。段页式管理机制结合了段式管理和页式管理的优点。程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。



**分页机制和分段机制的共同点和区别**

1. **共同点** ：

- - 分页机制和分段机制都是为了提高内存利用率，较少内存碎片。
  - 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。

1. **区别** ：

- - 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
  - 目的不同：分页仅仅是为了满足操作系统内存管理的需求，主要用于提高内存的利用率，消除外零头，抑制内零头；实现虚拟内存，从而获得更大的地址空间，而段是逻辑信息的单位，在程序中可以体现为代码段（子函数），数据段，有利于**模块化**程序设计。
  - 对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。
  - 地址空间的维度：对于用户来说，分页是一维地址空间，分段是二维的（第几段的第几行）。例如分页例题1502，1502/页的大小可以算出页号和页内偏移量



####  页面置换算法

👨‍💻**面试官** ：虚拟内存管理很重要的一个概念就是页面置换算法。那你说一下 **页面置换算法的作用?常见的页面置换算法有哪些?**

🙋 **我** ：

这个题目经常作为笔试题出现，网上已经给出了很不错的回答，我这里只是总结整理了一下。

地址映射过程中，若在页面中发现所要访问的页面不在内存中，则发生缺页中断 。

**缺页中断** 就是要访问的**页**不在主存，需要操作系统将其调入主存后再进行访问。 在这个时候，被内存映射的文件实际上成了一个分页交换文件。

**==当发生缺页中断时，如果当前内存中并没有空闲的页面==**，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。

- **OPT 页面置换算法（最佳页面置换算法）** ：最佳(Optimal, OPT)置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面,这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。
- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。
- **LRU （Least Currently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** :  该置换算法选择在之前时期使用最少的页面作为淘汰页。

**==要会写LRU和LFU==**



# 数据库

## 索引

**索引是一种用于快速查询和检索数据的数据结构。通常在涉及到文件的管理的应用都会有索引，比如数据库，操作系统文件管理，对象存储。**常见的索引结构有: B树， B+树和Hash。



## 事务

### 事务的四大特性

**1. 原子性（Atomicity）**

事务被视为不可分割的最小单元，**事务的所有操作要么全部提交成功，要么全部失败回滚。**

**回滚可以用回滚日志（Undo Log）来实现，**回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。

**2. 一致性（Consistency）**

**所有事务对同一个数据的读取结果都是相同的。**

**3. 隔离性（Isolation）**

**一个事务所做的修改在最终提交以前，对其它事务是不可见的。**

**4. 持久性（Durability）**

一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失。

**系统发生奔溃可以用重做日志（Redo Log）进行恢复**，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。



## 存储引擎

```sql
#查看MySQL提供的所有存储引擎 
show engines;

#我们也可以通过下面的命令查看默认的存储引擎。
show variables like '%storage_engine%';

#查看表的存储引擎，表的Engines项为表的引擎
show table status like "table_name" ;
```

### MyISAM和InnoDB的区别

- **事务：InnoDB 是事务型的，支持提交、回滚和紧急恢复功能来保护数据安全。**

- **并发：MyISAM 只支持表级锁，并发性差，而 InnoDB 还支持行级锁。**

- **索引：InnoDB 支持外键(B+树存主键的值)**  

- **数据存储：InnoDB是聚簇索引，MyISAM不是。**辅助索引也不同----InnoDB的辅助索引data域存储相应记录主键的值而不是地址。

- **是否支持MVCC：仅 InnoDB 支持。**应对高并发事务, MVCC比单纯的加锁更高效；MVCC只在 READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作；MVCC可以使用乐观(optimistic)锁和悲观(pessimistic)锁来实现；各数据库中MVCC实现并不统一。

- **备份：InnoDB 支持在线热备份。** 热备份是系统处于正常运转状态下的备份，MySQL的其他存储引擎不支持热备份，要获取一致性视图需要停止对所有表的写入，而在读写混合场景中，停止写入可能也意味着停止读取。

- **崩溃恢复：宕机后，InnoDB崩溃修复能力更强，而且恢复的速度也更快。**

- 其它特性：MyISAM提供全文索引、压缩、空间函数。

  

MySQL高性能》上面有一句话这样写到:

> 不要轻易相信“MyISAM比InnoDB快”之类的经验之谈，这个结论往往不是绝对的。在很多我们已知场景中，InnoDB的速度都可以让MyISAM望尘莫及，尤其是用到了聚簇索引，或者需要访问的数据都可以放入内存的应用。

一般情况下我们选择 InnoDB 都是没有问题的，但是某些情况下你并不在乎可扩展能力和并发能力，也不需要事务支持，也不在乎崩溃后的安全恢复问题的话，选择MyISAM也是一个不错的选择。但是一般情况下，我们都是需要考虑到这些问题的。



### 如何选取存储引擎

**MyISAM的适合场景**

- 频繁执行全表count语句。select count(*) from table 
  - MyISAM用一个变量保存了表的行数。InnoDB需要扫描统计

- **对数据进行增删改的频率不高，查询非常频繁的时候**
  - 增删改涉及锁表操作，每次都是表锁，并发性能很差

- 没有事务

**InnoDB适合的场景**

- 数据增删改查都频繁

- 可靠性要求比较高，要求支持事务的系统



如果只是临时存放数据，数据量不大，并且不需要较高的数据安全性，可以选择将数据保存在内存中的Memory引擎，MySQL中使用该引擎作为临时表，存放查询的中间结果

如果只有INSERT和SELECT操作，可以选择Archive，Archive支持高并发的插入操作，但是本身不是事务安全的。Archive非常适合存储归档数据，如**记录日志信息可以使用Archive。**



《MySQL高性能》上面有一句话这样写到：

不要轻易相信“MyISAM比InnoDB快”之类的经验之谈，这个结论往往不是绝对的。在很多我们已知场景中，InnoDB的速度都可以让MyISAM望尘莫及，尤其是用到了聚簇索引，或者需要访问的数据都可以放入内存的应用。

一般情况下我们选择 InnoDB 都是没有问题的，但是某些情况下你并不在乎可扩展能力和并发能力，也不需要事务支持，也不在乎崩溃后的安全恢复问题的话，选择MyISAM也是一个不错的选择。但是一般情况下，我们都是需要考虑到这些问题的。



### 索引使用规范

**1. 限制每张表上的索引数量,建议单张表索引不超过 5 个**

**2 禁止给表中的每一列都建立单独的索引**

**3. 每个 Innodb 表必须有个主键**

**4. 常见索引列建议**

- 出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列
- 包含在 ORDER BY、GROUP BY、DISTINCT 中的字段
- 并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好
- 多表 join 的关联列

**5.如何选择索引列的顺序**

**区分度最高，使用最频繁，字段长度最小的往左边放。**

**6. 避免建立冗余索引和重复索引（增加了查询优化器生成执行计划的时间）**

**7. 对于频繁的查询优先考虑使用覆盖索引**

覆盖索引：就是包含了所有查询字段 (where,select,ordery by,group by 包含的字段) 的索引

**覆盖索引的好处：**

- **避免 Innodb 表进行索引的二次查询**
- **可以把随机 IO 变成顺序 IO 加快查询效率:** 覆盖索引是按键值的顺序存储的。

**8.尽量避免使用外键约束**

- 不建议使用外键约束（foreign key），但一定要在表与表之间的关联键上建立索引
- 外键可用于保证数据的参照完整性，但建议在业务端实现
- 外键会影响父表和子表的写操作从而降低性能

**避免使用子查询，可以把子查询优化为 join 操作**

通常子查询在 in 子句中，且子查询中为简单 SQL(不包含 union、group by、order by、limit 从句) 时,才可以把子查询转化为关联查询进行优化。

**子查询性能差的原因：**

子查询的结果集无法使用索引，通常子查询的结果集会被存储到临时表中，不论是内存临时表还是磁盘临时表都不会存在索引，所以查询性能会受到一定的影响。特别是对于返回结果集比较大的子查询，其对查询性能的影响也就越大。

由于子查询会产生大量的临时表也没有索引，所以会消耗过多的 CPU 和 IO 资源，产生大量的慢查询。

**WHERE 从句中禁止对列进行函数转换和计算**

对列进行函数转换或计算时会导致无法使用索引



### 数据库基本设计规范

**1. 所有表必须使用 Innodb 存储引擎**

没有特殊要求（即 Innodb 无法满足的功能如：列存储，存储空间数据等）的情况下，所有表必须使用 Innodb 存储引擎（MySQL5.5 之前默认使用 Myisam，5.6 以后默认的为 Innodb）。

Innodb 支持事务，支持行级锁，更好的恢复性，高并发下性能更好。

**2. 尽量控制单表数据量的大小,建议控制在 500 万以内。**

500 万并不是 MySQL 数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。

可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小

**3.尽量做到冷热数据分离,减小表的宽度**

MySQL 限制每个表最多存储 4096 列，并且每一行数据的大小不能超过 65535 字节。

**减少磁盘 IO,保证热数据的内存缓存命中率**（表越宽，把表装载进内存缓冲池时所占用的内存也就越大,也会消耗更多的 IO）；

更有效的利用缓存，避免读入无用的冷数据；

经常一起使用的列放到一个表中（避免更多的关联操作）。

**4.谨慎使用 MySQL 分区表**

分区表在物理上表现为多个文件，在逻辑上表现为一个表；谨慎选择分区键，跨分区查询效率可能更低；

建议采用物理分表的方式管理大数据。

- 数据库和表的字符集统一使用 UTF8
- 所有表和字段都需要添加注释
- 禁止在表中建立预留字段
- 禁止在数据库中存储图片,文件等大的二进制数据
- 禁止在线上做数据库压力测试
- 禁止从开发环境,测试环境直接连接生产环境数据库



### 字段设计规范

**1.优先选择符合存储需要的最小的数据类型**

**2.尽可能把所有列定义为 NOT NULL**

**3.同财务相关的金额类数据必须使用 decimal 类型 --价格**

- 非精准浮点：float,double
- 精准浮点：decimal

**使用 TIMESTAMP(4 个字节) 或 DATETIME 类型 (8 个字节) 存储时间**

**避免使用 TEXT,BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据**

**避免使用 ENUM 类型**



# 计算机网络

## 传输层

### TCP与UDP的区别

- TCP面向连接，UDP无连接。
- TCP 是一对一的两点服务，UDP 支持一对一、一对多、多对多的交互通信。
- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。UDP 尽最大努力交付，不保证可靠交付数据。
- TCP 有拥塞控制和流量控制机制，UDP 没有
- TCP面向字节流，UDP是报文段
- TCP传输所需资源多，传输慢；UDP传输所需资源少，传输快。
- TCP首部长度可变（20-60字节） UDP首部固定8字节

### TCP与UDP应用场景

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- HTTP/HTTPS SSH
- FTP文件传输、POP3 SMTP 发送和接收邮件、TELNET远程登录等场景。

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 DNS 、SNMP 等
- 即时通信：视频、音频等多媒体通信
- **DHCP**（Dynamic Host Configuration Protocol，动态主机配置协议），动态配置IP地址。



#### 如何理解TCP面向字节流，UDP面向报文段？

**问题的关键在于TCP是有缓冲区**，作为对比，UDP面向报文段是没有缓冲区的。

TCP是面向字节流的，它把上面应用层交下来的数据看成无结构的字节流来发送，可以想象成流水形式的，发送方TCP会将数据放入**“蓄水池”（缓冲区）**，等到可以发送的时候就发送，不能发送就等着，跟应用层写下来的报文长度没有任何关系，TCP会根据当前网络的拥塞状态来确定每个报文段的大小。并且在TCP建立连接前两次握手的SYN报文中选项字段的MSS值，通信双方商定通信的最大报文长度。如果应用层交付下来的数据过大，就会对数据分段，然后发送。

UDP是面向报文的，发送方的UDP对应用层交下来的报文，无论多长，既不合并，也不拆分，只是在其上面加上首部后就交给了下面的网络层，也就是说无论应用层交给UDP多长的报文，它统统发送，一次发送一个。而对接收方，接到后直接去除首部，交给上面的应用层就完成任务了。因此，它需要应用层控制报文的大小。UDP发送端调用了几次write，接收端必须用相同次数的read读完。



#### 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

**MSS主要为了TCP的超时重传。**如果只有IP层的分片，一片丢失之后，整个IP报文的所有分片都得重传。为了达到最佳的传输效能 TCP 协议在**建立连接的时候通常要协商双方的 MSS 值**，当 TCP 层发现数据超过 MSS 时，则就先会进行分段，如果一段丢失，只会超时重传丢失的那一段。



### TCP、UDP头部格式

**TCP首部20-60字节** 

**固定20字节：源端口目的端口(4) 序列号(4) 确认号(4)  窗口(2)  校验和(2) 首部长度(4b) 标记位(6b) 紧急指针(2) **

**可变： 选项   填充**

**控制位：**

- ACK：确认序号有效。TCP 规定除了最初建立连接时的 SYN 包之外该位必须设置为 1 。
- **RST：TCP 连接中出现异常必须强制断开连接。记忆：RESET**
- SYN：发起一个新连接。
- FIN：释放一个连接。
- **PSH：接收方应该尽快将这个报文交给应用层。**
- **URG：紧急指针（urgent pointer）有效。**

**2字节的紧急指针什么用？**

**紧急指针指出的是紧急数据在报文段中结束的位置**

有时一些应用程序在某些紧急情况下（如在某些连接中进行强制中断）要求在接收方在没有处理完数据之前就能够发送一些紧急数据，这就使得发送方将CODE字段的URG置为1，即紧急指针字段有效，这样可以不必考虑你发送的紧急数据在数据流中的位置，也就是相当于**优先级最高**。



UDP 协议真的非常简单，头部只有 8 个字节，UDP 的头部格式如下：

- 目标(2)和源端口(2)：主要是告诉 UDP 协议从哪个进程来，应该把报文发给哪个进程。
- 包长度(2)：该字段保存了 UDP 首部的长度跟数据的长度之和。
- 校验和(2)：校验和是为了提供可靠的 UDP 首部和数据而设计。

**为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？**

TCP 有**可变长**的「选项」字段，而 UDP 头部长度则是**不会变化**的，无需多一个字段去记录 UDP 的首部长度。



### TCP协议如何保证可靠传输 ⭐

1. **校验和**：发送方在发送数据之前计算检验和，并进行校验和的填充。接收方，收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方的进行比对
2. **确认应答与序列号**：TCP传输时将每个字节的数据都进行了编号，TCP传输的过程中，每次接收方收到数据后，都会对传输方进行确认应答，也就是发送ACK报文，报文中包含对应的确认序列号。
3. **超时重传**：发送方在发送完数据后等待一个时间，时间到达没有接收到ACK报文，那么对刚才发送的数据进行重新发送。  
4. **连接管理**：连接管理就是三次握手与四次挥手的过程
5. **流量控制**：TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）。
6. **拥塞控制**：发送端在刚开始就发送大量的数据，那么就可能造成网络拥塞。所以TCP引入了慢启动的机制，在开始发送数据时，先发送少量的数据探路。**快速重传**
7. **ARQ协议**： **自动重传请求**（Automatic Repeat-reQuest，ARQ）。ARQ包括停止等待ARQ协议和连续ARQ协议。
   - 停止等待ARQ协议：每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
   - 连续ARQ协议：发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。缺点：Go-Back-N（回退 N），需要退回来重传已经发送过的 N 个消息。



#### 流量控制

**TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。**

发送方不能无脑的发数据给接收方，要考虑接收方处理能力。**TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力——确认报文中的窗口字段，控制发送的数据量，这就是所谓的流量控制。**

#### 拥塞控制

前面的流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。

**拥塞控制**，目的是**避免「发送方」的数据填满整个网络。**

**拥塞窗口 cwnd**是发送方维护的一个的状态变量，它会根据**网络的拥塞程度动态变化的**。

流量控制要求发送方发送的数据不超过接收方的rwnd，拥塞控制要求发送方发送的数据不超过拥塞窗口，因此发送窗口的值是swnd = min(cwnd, rwnd)。

拥塞窗口 cwnd 变化的规则：

- 只要网络中没有出现拥塞，cwnd 就会增大；
- 但网络中出现了拥塞，cwnd 就减少；

**那么怎么知道当前网络是否出现了拥塞呢？**

其实只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**

拥塞控制主要是四个算法：

- **慢开始** 成倍增长
- **拥塞避免**    直到遇到拥塞避免的开始ssthresh，变成线性增长
- **拥塞发生-超时重传**  遇到超时，cwnd 重置为 1  拥塞避免的开始ssthresh设为 cwnd/2。
- **快速恢复** 遇到3ACK  拥塞避免的开始设为cwnd/2，cwnd设为cwnd/2 + 3



### TCP建立连接：三次握手

- 第一次握手：客户端–发送带有 SYN 标志的数据包。
- 第二次握手：服务端–发送带有 SYN/ACK 标志的数据包。
- 第三次握手：客户端–发送带有带有 ACK 标志的数据包。

#### 为什么TCP连接的时候是3次？2次不可以吗？

**1. 同步双方的初始序列号，双方都确认自己与对方的发送与接收是正常的**

**2. 依靠第三次握手才可以阻止重复连接**

在**网络拥堵**情况下，客户端可能连续发送多次 SYN 建立连接的报文，服务端会**建立多个冗余的无效链接，造成不必要的资源浪费。**

为了避免这种情况，需要第三次握手来只确认建立最后发送的连接。如果不是最新的连接，则第三次握手发送的报文是**RST**报文，以此中止这个冗余连接；如果是最新的，则第三次发送的报文是**ACK**报文，通信双方就会成功建立连接。

#### 为什么客户端和服务端的初始序列号 ISN 是不相同的

每次建立连接前重新初始化一个序列号主要是**为了通信双方能够根据序号将不属于本连接的报文段丢弃。**

### TCP断开连接：四次挥手

断开一个 TCP 连接则需要“四次挥手”：

- 客户端-发送一个 FIN，用来关闭客户端到服务器的数据传送
- 服务器-收到这个 FIN，它发回一 个 ACK，确认序号为收到的序号加1 。服务端进入**CLOSE-WAIT（关闭等待）**
- 服务器-关闭与客户端的连接，发送一个FIN给客户端。
- 客户端-发回 ACK 报文确认，进入**TIME-WAIT（时间等待）**状态。
  - 服务器收到了 ACK 应答报文后，就进入了 CLOSED 状态，至此服务端已经完成连接的关闭。
  - 客户端在经过 **2MSL最长报文段寿命**后，自动进入 CLOSED 状态，至此客户端也完成连接的关闭。

#### 为什么TCP连接的时候是3次，关闭的时候却是4次？

**服务端通常需要等待完成数据的发送和处理**，所以服务端的 ACK 和 FIN 一般都会分开发送，从而比三次握手导致多了一次。

#### 为什么需要 TIME_WAIT 状态？

- **确保服务器端的最后一个确认报文(ACK)能够到达，从而可靠地关闭服务端的连接**。如果 B 没收到 A 发送来的确认报文，那么就会重新发送连接释放请求报文，A 等待一段时间就是为了处理这种情况的发生。
- **防止上一次连接中的包，迷路后重新出现，影响新连接。**等待一段时间是为了让**本连接持续时间内所产生的所有报文都从网络中消失**，使得下一个新的连接不会出现旧的连接请求报文。

#### 为什么 TIME_WAIT 等待的时间是 2MSL？

MSL 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，**超过这个时间报文将被丢弃。 一来一去的最大时间是2MSL**

2MSL 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 2MSL 时间将重新计时。

#### TIME_WAIT 过多有什么危害？端口/内存

危害1：客户端受**端口资源**限制。

危害2：服务端受**系统资源（内存）**限制：系统资源被占满，线程池处理不了那么多一直不断的连接了。

#### 如何处理TIME_WAIT过多

**简单来说，就是打开系统的TIMEWAIT重用和快速回收。还不行的话，尝试修改TCP连接的相关参数（keepalive time，开放端口数，syn队列大小）** 都在`/etc/sysctl.conf`

如果尽量处理了，还是解决不了问题，仍然拒绝服务客户的部分请求，可以采取**负载均衡**来抗这些高并发的短请求。

#### close_wait过多

现象:通过`netstat -napt` 查看TCP连接状态，查看与61616相关的连接状况，发现130多个CLOSE_WAIT

##### close_wait过多原因

**1. socket忙于读写，处理不过来了。**

**2. 写的程序有问题：socket完毕之后，忘记调用close方法。**

##### close_wait过多的解决方案

**参数层面**

**可能是客户端调用close之后挂掉了。可以设置TCP的连接时长keep_alive_time**还有tcp监控连接的频率以及连接没有活动多长时间被迫断开连接。由于KeepLive在Windows操作系统下默认是7200秒，也就是2个小时才清理一次。

**代码层面：**

**第一：使用完socket调用close方法；**

**第二：socket读控制，当读取的长度为0时（读到结尾），立即close；**

第三：如果read返回-1，出现错误，检查error返回码，有三种情况：INTR（被中断，可以继续读取），WOULDBLOCK（表示当前socket_fd文件描述符是非阻塞的，但是现在被阻塞了），AGAIN（表示现在没有数据稍后重新读取）。**如果不是AGAIN，立即close**



## 常见网络攻击

### SYN攻击

**攻击者伪造大量的虚假ip，向Server发送大量SYN报文。**Server在接收到SYN包后，会返回响应，并进入SYN_RECV状态，等待客户端的确认。

**伪造的ip不给予ACK响应**，于是Server以为数据包丢失，不断重发，直到超时。这些伪造的SYN包会**长期占用SYN队列**，使得服务器不能为正常用户服务。引起网络拥堵甚至网络瘫痪。

**当服务器上有大量的半连接且ip为随机的，可以确认是受到了SYN攻击。**

#### 如何避免SYN攻击

**1. 修改 Linux 内核关于SYN队列的参数**

如：修改`SYN_RCVD` 状态连接的最大个数`net.ipv4.tcp_max_syn_backlog`

**2. 设置tcp_syncookies参数**

```sh
vim /etc/sysctl.conf
#加入以下内容：
net.ipv4.tcp_syncookies = 1 
```

**相当于syn等待队列满了之后，新连接不需要进入SYN队列，直接处理。服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，直接放入到「 Accept 队列」。 **



# 设计模式

## 七大设计原则

[链接](./docs/system-design/设计模式/设计原则.md)

| **设计原则**     | **一句话归纳**                                               | **目的**                                       |
| ---------------- | ------------------------------------------------------------ | ---------------------------------------------- |
| **开闭原则**     | **对扩展开放，对修改关闭**                                   | **降低维护带来的新风险**                       |
| **依赖倒置原则** | **高层不应该依赖低层，要面向接口编程**                       | **更利于代码结构的升级扩展**                   |
| **单一职责原则** | **一个类只干一件事，实现类要单一**                           | **便于理解，提高代码的可读性**                 |
| **接口隔离原则** | **一个接口只干一件事，接口要精简单一**                       | **功能解耦，高聚合、低耦合**                   |
| **迪米特法则**   | **不该知道的不要知道，一个类应该保持对其它对象最少的了解，降低耦合度** | **只和朋友交流，不和陌生人说话，减少代码臃肿** |
| **里氏替换原则** | **不要破坏继承体系，子类重写方法功能发生改变，不应该影响父类方法的含义** | **防止继承泛滥**                               |
| **合成复用原则** | **尽量使用组合或者聚合关系实现代码复用，少使用继承**         | **降低代码耦合**                               |

## 结构型设计模式

### 代理模式 🔥

**核心：使用代理对象来代替对真实对象(real object)的访问，这样就可以在不修改原目标对象的前提下，扩展目标对象的功能。**

#### 静态代理和动态代理的对比

1. **灵活性** ：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。另外，静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！
2. **JVM 层面** ：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。

#### 静态代理

代理对象和目标对象共同实现一个抽象接口，客户通过代理对象来访问目标对象的方法，代理对象控制访问，并且做增强。相当于在目标对象上面包了一层，做一些公共的事情，并且控制对目标对象的访问。

**静态代理中，我们对目标对象的每个方法的增强都是手动完成的，非常不灵活（_比如接口一旦新增加方法，目标对象和代理对象都要进行修改_）且麻烦(_需要对每个目标类都单独写一个代理类_)。**

#### 动态代理——AOP的核心！

**推荐阅读：[知乎-动态代理的作用是什么](https://www.zhihu.com/question/20794107/answer/23330381)**

**通过反射，在代码运行期间动态生成代理类，代理的是接口，一个动态代理可以代理很多类！为所有目标类提供一些通用的增强方法，比如插入日志-AOP。**

##### JDK 动态代理和 CGLIB 动态代理对比

1. **一个基于接口实现，一个基于类的继承实现** 

   JDK动态代理只能对实现了接口的类生成代理，而不能针对类。

   CGLIB是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法。因此对于final类或方法，是无法继承的。

2. **JDK效率更高**

   JDK 和 CGLib 都是在运行期生成字节码，JDK 是直接写 Class 字节码，CGLib 使用 ASM 框架写 Class 字节码，Cglib 代理实现更复杂，生成代理类比 JDK 效率低。每一次jdk版本升级，jdk代理效率都得到提升，而CGLIB代理消息确有点跟不上步伐。

**Spring 中的 AOP 模块中：如果目标对象实现了接口，则默认采用 JDK 动态代理，否则采用 CGLIB 动态代理。**

##### JDK动态代理

**在 Java 动态代理机制中 `InvocationHandler` 接口和 `Proxy` 类是核心。**都在`java.lang.reflect`包下面。

步骤一：定义一个接口及其实现类；也就是被代理对象。

步骤二：自定义 `InvocationHandler` 并重写`invoke`方法，在 `invoke` 方法中我们会调用原生方法（被代理类的方法）并自定义一些处理逻辑；

实现`InvocationHandler` 来自定义处理逻辑。 当我们的动态代理对象调用一个方法时候，这个方法的调用就会被转发到实现`InvocationHandler` 接口类的 `invoke` 方法来调用。

```java
public interface InvocationHandler {
    //当你使用代理对象调用方法的时候实际会调用到这个方法
    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;
}
```

`invoke()` 方法有下面三个参数：

1. **proxy** :动态生成的代理类
2. **method** : 与代理类对象调用的方法相对应
3. **args** : 当前 method 方法的参数

也就是说：**你通过`Proxy` 类的 `newProxyInstance()` 创建的代理对象在调用方法的时候，实际会调用到实现`InvocationHandler` 接口的类的 `invoke()`方法。**在invoke方法中调用代理对象的同名方法，并且做一些增强：比如在方法执行前后做什么事情。

步骤三：通过 `Proxy.newProxyInstance(ClassLoader loader,Class<?>[] interfaces,InvocationHandler h)` 方法创建代理对象；

`Proxy` 类中使用频率最高的方法是：`newProxyInstance()` ，这个方法主要用来生成一个代理对象。传入目标对象的Classloader，接口，代理对象的`InvocationHandler`，就可以动态生成代理对象。

```java
public static Object newProxyInstance(ClassLoader loader,
                                      Class<?>[] interfaces,
                                      InvocationHandler h)
    throws IllegalArgumentException
```

这个方法一共有 3 个参数：

1. **loader** :类加载器，用于加载代理对象。
2. **interfaces** : 被代理类实现的一些接口；
3. **h** : 实现了 `InvocationHandler` 接口的对象；

**动态生成代理类过程**

复制传入的接口，通过接口和类加载器，直接拼接生成字节数组class文件，然后调用native方法defineclass生成clazz对象，创建出了代理的类clazz。然后通过反射获取到代理类clazz的构造函数，通过这个构造函数new一个代理对象，构造函数的参数是InvocationHandler。当代理对象的方法被调用时，会调用InvocationHandler的invoke方法，调用目标对象的方法，并实现增强。

**举例：**

一般会把步骤二和步骤三写到一起：

```java
public class ProxyInvocationHandler implements InvocationHandler {
   private Object target;

   public void setTarget(Object target) {
       this.target = target;
  }

   //生成代理类
   public Object getProxy(){
       return Proxy.newProxyInstance(this.getClass().getClassLoader(),
               target.getClass().getInterfaces(),this);
  }

   // proxy : 代理类
   // method : 代理类的调用处理程序的方法对象.
   public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
       log(method.getName());
       Object result = method.invoke(target, args);
       return result;
  }

   public void log(String methodName){
       System.out.println("执行了"+methodName+"方法");
  }
}
```

```java
public class Test {
   public static void main(String[] args) {
       //真实对象
       UserServiceImpl userService = new UserServiceImpl();
       //代理对象的调用处理程序
       ProxyInvocationHandler pih = new ProxyInvocationHandler();
       //设置要代理的对象 可以是任意对象！！
       pih.setTarget(userService);
       UserService proxy = (UserService)pih.getProxy(); //动态生成代理类！
       //可以换成接口中的任意方法！！！
       proxy.delete();  
  }
}
```

##### CGLIB 动态代理

**在 CGLIB 动态代理机制中 `MethodInterceptor` 接口和 `Enhancer` 类是核心。**

通过 `Enhancer`类来动态获取被代理类，当代理类调用方法的时候，实际调用的是 `MethodInterceptor` 中的 `intercept` 方法。

步骤一：自定义 `MethodInterceptor` 并重写 `intercept` 方法，`intercept` 用于拦截增强被代理类的方法，和 JDK 动态代理中的 `invoke` 方法类似；

```java
public interface MethodInterceptor extends Callback{
    // 拦截被代理类中的方法
    public Object intercept(Object obj, java.lang.reflect.Method method, Object[] 	
                            args,MethodProxy proxy) throws Throwable;
}
```

1. **obj** :目标对象（需要增强的对象）
2. **method** :被拦截的方法（需要增强的方法）
3. **args** :方法入参
4. **methodProxy** :用于调用原始方法

步骤二：通过 `Enhancer` 类的`setSuperclass`设置目标对象，`setCallback`传入`MethodInterceptor` 设置回调对象，然后 `create()`创建代理对象；

```java
net.sf.cglib.proxy.Enhancer;
Enhancer enhancer = new Enhancer();
// 设置enhancer对象的父类  也就是被代理的对象
enhancer.setSuperclass(HelloService.class);
// 设置enhancer的回调对象
enhancer.setCallback(new MyMethodInterceptor());
//创建代理对象！
HelloService proxy= (HelloService)enhancer.create();
```



# SSM框架

## MyBatis

**ResultMap 结果映射——解决属性名和字段名不一致的问题**

```xml
<!-- mybatis-config.xml 中 -->
<typeAlias type="com.mkx.pojo.User" alias="User"/>

<!--结果集映射 把UserMap映射为User——映射的关系 -->
<resultMap id="UserMap" type="User">
    <!--column数据库中的字段，property实体类中的属性-->
    <result column="id" property="id"/>
    <result column="name" property="name"/>
    <result column="pwd" property="password"/>
</resultMap>

			<!--这里去掉了resultType属性，用了resultMap之后不需要了-->
<select id="getUserById" resultMap="UserMap">
    select * from mybatis.user where id = #{id}
</select>
```





# Git

```sh
#移除文件的追踪
git rm --cached file名 #把文件从版本库里移除   -r folder名
vim .gitignore #然后把文件添加到gitignore中，再次commit，push的时候就没有了
```





# tips

- 写程序应该80%的时间在思考，20%的时间敲代码。不应该反过来